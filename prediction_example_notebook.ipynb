{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fasta_utils import *\n",
    "from utils.proteome_process import *\n",
    "from utils.prefetcher import *\n",
    "from utils.network_utils import *\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import hdbscan\n",
    "import faiss\n",
    "from sklearn.metrics.pairwise import cosine_distances,euclidean_distances\n",
    "import numpy as np\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swapnesh/anaconda3/envs/esmfold/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (2,20,29,33,40,57,62,63,73) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"/path/to/folder\" # path to folder where the databse is downloaded ~250mb\n",
    "\n",
    "model_name = \"650m\" # use the corresponding model\n",
    "db_zarr_path = os.path.join(data_folder , f\"ESM2_{model_name}_1Sept24_{model_name}.zarr\")\n",
    "faiss_index_path = os.path.join(data_folder , f\"ESM2_{model_name}_1Sept24_{model_name}.zarrfaiss_index.bin\")\n",
    "eps_values_path = os.path.join(data_folder , f\"ESM2_{model_name}_1Sept24_{model_name}_eps_values_flat_clusters.npy\")\n",
    "\n",
    "HieVi_INPHARED_ordered_annotation = \"HieVi_INPHARED_ordered_annotation.csv\"\n",
    "\n",
    "db_zarr_store = zarr.open(db_zarr_path,'r')\n",
    "db_accessions = db_zarr_store['accessions'][:]\n",
    "\n",
    "# load annotation file for HieVi vector database\n",
    "annotations = pd.read_csv(HieVi_INPHARED_ordered_annotation)\n",
    "annotations= annotations[annotations[\"Accession\"].isin(db_accessions)]\n",
    "annotations = annotations.set_index(\"Accession\").loc[db_accessions].reset_index()\n",
    "\n",
    "eps_values = np.load(eps_values_path)\n",
    "index = faiss.read_index(faiss_index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate query vectors and save in the same folder\n",
    "\n",
    "filename = \"/path/to/proteome_multifasta.faa\"\n",
    "\n",
    "# @title Compute phage representations\n",
    "expt_name = \"TEST\"  # @param {type:\"string\"}\n",
    "expt_name = expt_name.replace(' ','_')\n",
    "output_folder = os.path.dirname(filename) + os.sep \n",
    "fasta_path = filename\n",
    "#model_name = \"3b\" # This colab works for 650m only\n",
    "mode = \"mean\"\n",
    "query_zarr_path = os.path.join(output_folder,f\"{expt_name}_{model_name}.zarr\")\n",
    "!python GenPhageRepresentationsESM2.py {expt_name} {output_folder} {fasta_path} {model_name} {mode}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/swapnesh/Downloads/TEST_650m.zarr\n"
     ]
    }
   ],
   "source": [
    "# load query vectors\n",
    "query_zarr_path = f\"{output_folder}{expt_name}_{model_name}.zarr\"\n",
    "print(query_zarr_path)\n",
    "query_zarr_store = zarr.open(query_zarr_path,'r')\n",
    "query_vectors = query_zarr_store['vectors_mean'][:]*1.0\n",
    "query_accessions = query_zarr_store['accessions'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show nearest neighbours and distances for sanity check\n",
    "#distances, indices = index.search(query_vectors, 4)\n",
    "#print(db_accessions[indices],distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 102 Accessions from database.\n"
     ]
    }
   ],
   "source": [
    "# extract nearest neighbours\n",
    "\n",
    "hievi_cluster_prefix = 'HC_'\n",
    "k_neighbours = 8 # \n",
    "distance_threshold = 0.023 # \n",
    "distance_in_tree = 2\n",
    "\n",
    "distances, indices = index.search(query_vectors, k_neighbours)\n",
    "valid_idx = distances[:,0] < distance_threshold\n",
    "invalid_idx = np.logical_not(valid_idx)\n",
    "\n",
    "if len(np.where(invalid_idx)[0]):\n",
    "    print('Cannot classifiy: ' ,len(np.where(invalid_idx)[0]))\n",
    "    invalid_query_df = pd.DataFrame({\"Accession\": query_accessions[invalid_idx]})\n",
    "    invalid_query_df.to_csv(query_zarr_path[:-5] + \"_HieVi_Unclassifieds.csv\")\n",
    "\n",
    "all_indices = np.unique(np.ravel(np.array(indices[valid_idx])))\n",
    "subset_db_vectors = np.array([db_zarr_store['vectors_mean'][i] for i in all_indices])\n",
    "distances, indices = index.search(subset_db_vectors, k_neighbours)\n",
    "\n",
    "\n",
    "D1 = np.squeeze(distances)\n",
    "I1 = np.squeeze(indices)\n",
    "\n",
    "all_indices = np.unique(np.array(I1))\n",
    "all_nearest_accessions = db_accessions[all_indices]\n",
    "\n",
    "#subset_db_vectors = db_zarr_store['vectors_mean'][all_indices,:]\n",
    "\n",
    "subset_db_vectors = np.array([db_zarr_store['vectors_mean'][i] for i in all_indices])\n",
    "\n",
    "print(f\"Loaded {subset_db_vectors.shape[0]} Accessions from database.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Combine query and nearest phages from database data\n",
    "\n",
    "# Get nearest accessions in tree\n",
    "nearest_accessions = annotations[annotations[\"Accession\"].isin(all_nearest_accessions)]\n",
    "nearest_accessions = nearest_accessions.set_index(\"Accession\").loc[all_nearest_accessions].reset_index()\n",
    "\n",
    "# Combine query and database data\n",
    "query_df = pd.DataFrame({\"Accession\": query_accessions[valid_idx],\"Query\": \"yes\"})\n",
    "annotation_df = pd.concat([nearest_accessions, query_df], axis=0)\n",
    "mprs = np.concatenate((subset_db_vectors, query_vectors[valid_idx]), axis=0)\n",
    "\n",
    "# Perform clustering\n",
    "# dist_scaled = euclidean_distances(mprs).astype(\"double\")\n",
    "# clusterer = hdbscan.HDBSCAN(\n",
    "#     min_cluster_size=2,\n",
    "#     n_jobs=32,\n",
    "#     min_samples=1,\n",
    "#     allow_single_cluster=False,\n",
    "#     cluster_selection_method=\"leaf\",\n",
    "#     metric=\"precomputed\",\n",
    "#     gen_min_span_tree=True\n",
    "# )\n",
    "# clusterer.fit(dist_scaled)\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=2,\n",
    "    min_samples=1,\n",
    "    allow_single_cluster=False,\n",
    "    cluster_selection_method=\"leaf\",\n",
    "    metric=\"euclidean\",\n",
    "    gen_min_span_tree=True\n",
    ")\n",
    "clusterer.fit(mprs)\n",
    "\n",
    "annotation_df[\"HieVi_cluster\"] = clusterer.labels_\n",
    "for i,eps in enumerate(eps_values):\n",
    "    annotation_df[hievi_cluster_prefix+str(i)] = clusterer.dbscan_clustering(cut_distance=eps,min_cluster_size=2)\n",
    "#annotation_df\n",
    "\n",
    "import re\n",
    "# Function to clean text\n",
    "# this is required for proper formatting of the gexf file, otherwise opening it in cytoscape fails\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)  # Allow dashes by including \"-\" in the character class\n",
    "    text = re.sub(r'%', '', text)  # Remove percent signs\n",
    "    text = text.strip()  # Remove leading/trailing spaces\n",
    "    return text    \n",
    "min_lambda = 1/0.023 # @param {type:\"slider\", min:-1, max:32, step:1}\n",
    "\n",
    "node_attributes = ['Accession',\"Query\", 'Virus_Description', 'Realm', 'Kingdom', 'Phylum',\n",
    "       'Class', 'Order', 'Family', 'Subfamily', 'Genus','Host_Enveloppe',\n",
    "       'Host_Isolation', 'Host_species', 'Host_order',\n",
    "       'Host_phylum', 'Molecule_type','HieVi_cluster', 'HC_0', 'HC_1',\n",
    "       'HC_2', 'HC_3', 'HC_4', 'HC_5', 'HC_6', 'HC_7', 'HC_8', 'HC_9', 'HC_10',\n",
    "       'HC_11']\n",
    "\n",
    "df = annotation_df[node_attributes].copy()\n",
    "# Apply cleaning to column names and all values\n",
    "df.columns = [clean_text(col) for col in df.columns]\n",
    "df = df.applymap(lambda x: clean_text(str(x)))  # Apply to all values\n",
    "\n",
    "\n",
    "min_lambda =13.00 # @param {type:\"slider\", min:-1, max:32, step:1}\n",
    "# Create and save network\n",
    "G = make_network(clusterer, df,min_lambda=min_lambda)\n",
    "nx.write_gexf(G, query_zarr_path[:-5] + \"_HieVi.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_642016/3112704641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Show the plot only if show=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/esmfold/lib/python3.7/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3410\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/esmfold/lib/python3.7/site-packages/plotly/io/_renderers.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnbformat\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4.2.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             raise ValueError(\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0;34m\"Mime type rendering requires nbformat>=4.2.0 but it is not installed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             )\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "# save a html for visualization (optional)\n",
    "from utils.plotter import *\n",
    "# Plot the graph for small graphs only\n",
    "show = True # @param {type:\"boolean\"}\n",
    "if len(df) > 2048:\n",
    "    show = False\n",
    "fig = plot_hierarchical_graph(G,\"radial\")\n",
    "# Save to HTML\n",
    "fig.write_html(query_zarr_path[:-5] + \"_HieVi.html\")\n",
    "\n",
    "# Show the plot only if show=True\n",
    "if show:\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esmfold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
